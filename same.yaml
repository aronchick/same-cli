# https://github.com/kubeflow/kfctl/blob/4c159515c4045c8f45667094de313a49b3767dda/pkg/kfapp/kustomize/testdata/kustomizeExample/metadata/expected/kustomization.yaml
apiVersion: projectsame.io/v1alpha1
metadata:
    name: MyFirstSameRun
    sha: a90eaf2
    labels:
        label1: value1
    version: 1.0.4
bases:
    - base
envfiles:
    - .env
resources:
    cluster_profile: highMem
    # nodePoodName: sameAgentPool
    # cores:
    #     requested: 20
    #     required: 10
    #     minimum_per_machine: 4
    # gpus:
    #     type: V100
    #     per_machine: 1
    # disks:
    #     - name: data_disk
    #       size: 10Gi
    #       volumeMount:
    #         mountPath: "/mnt/data_disk"
    #         name: volume
    #     - name: model_disk
    #       size: 10Gi
    #       volumeMount:
    #         mountPath: "/mnt/model_disk"
    #         name: volume
workflow:
    type: kubeflow
        kubernetesAPIServerURI: kubeflowpipelines.contoso.com/
        kubeflowVersion: 1.2
        kubeflowNamespace: kubeflow # Only support Kubeflow namespace
        services:
            - tensorflow_crd
            - pytorch_crd
        credentialFile: porter-kfp
pipeline:
    name: "my_great_pipeline"
    description: "a very good description goes here"
    package: "/home/bverst/src/work/kubeflow-pipeline-compiled.zip"
dataSets:
    - name: "DS1 name"
      type: remote
      url: "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
      makeLocalCopy: true
    - name: "DS2 name"
      type: remote
      url: "2.csv"
      makeLocalCopy: false

run: 
    name: "My Run"
    parameters:
        epochs: 1000
        batch_size: 100
